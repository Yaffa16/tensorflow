{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive textgenrnn Demo w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yaffa16/tensorflow/blob/master/Interactive_textgenrnn_Demo_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Interactive textgenrnn Demo w/ GPU\n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: December 2nd, 2018*\n",
        "\n",
        "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity, **for free on a GPU using Collaboratory!**\n",
        "\n",
        "For more about textgenrnn, you can visit [this GitHub repository](https://github.com/minimaxir/textgenrnn).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes.\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "outputId": "0a2b6edf-98d7-4919-f531-7c26b826be3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any text file** and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"/content/drive/My Drive/bg.txt\"\n",
        "model_name = 'gitagen'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkCzZ2ZMJyZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b2285fce-3e70-4e51-9245-5bbb13f09c39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "7c5509ba-0ab6-45eb-9afe-8c93e8587a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 87,898 character sequences.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "85/85 [==============================] - 11s 131ms/step - loss: 3.4625\n",
            "Epoch 2/20\n",
            "85/85 [==============================] - 5s 61ms/step - loss: 3.2534\n",
            "Epoch 3/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 3.2458\n",
            "Epoch 4/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 3.2273\n",
            "Epoch 5/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 3.1656\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "   aa n   a  aen   n   an  t    a n       no     e n  a t      n     t hh    e  n    n\n",
            "    an   at   n   a o nt      a in   rt\n",
            "Tn   i    n    n   a  n    o    nt      an     n     th    ense    n    n  a  n     e   aad  t  h    a  n     n    n e    \n",
            "Tn        n     n    a    t   he     n    a n  e  \n",
            "\n",
            " o  e n      n    n     o   anan    n    o   n      n t      n       n     n    na\n",
            " a  n    n    at     n   o       n o   n  d  n    n     n  t    a  ann     n    n    n   n     aadaal   n   i n     an    n t     a ta  ee   n   n    n     n     e aaan  a n    t    s    th       n  o    th     sheao \n",
            "\n",
            "  atoe   at     n     n      n \n",
            "TA    n      o   th    h      n     n      t es et    a h e e   at   n   \n",
            "TTA a  n    at   h  a t  h    n      at      a n   \n",
            "T   o    n t      n   n       n    ht ee e  a  a  th   e a   a  eaedte    n   n\n",
            "T e     n      n     en  ne      at   n   t    a a   ea an n  \n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "  d \n",
            "TAth    iltfh ra et   ht  aen \n",
            "At h wieh  i  the   aaate thhee eeene n eos  rlhrn  n \n",
            "Te srgn eanit   i thi  .   t  iho e\n",
            "A n  t  ne toh   h oelt  fa   nde e \n",
            "Woeeh no g in  e ine t   aa n es heeh s s hise\n",
            "o  nl a  n thoos   it sm  thoa fo\n",
            "T  anooat aito of   Vastni    aoats no ld\n",
            "a yno ano  an\n",
            "\n",
            "tah  naeo l sisncn\n",
            "Wtheooh  tes n !    oa e  n  dsa  ngsaoa  n    ea st n\n",
            "Aatrn    nr  t s  the  heih eaire ned a\n",
            "Ono   nd r  an irrg a c i  o  t   o\n",
            "Wh shihhn obr   le n  t   aisha em\n",
            "Bothf hetit  hoi  gr  c tho  is eeea tese  aoet stm\n",
            "TPinh   ,e  n ei t e \n",
            "hn atl hi tseh  et otee\n",
            "ere   o  - e i n \n",
            "\n",
            " ac ws s ls lnnaeeds sa aa to   ains rhae\n",
            "thh e eat  aacth te  s .  ne s  eaaeo\n",
            "Bchn n ee  nt  hfaes atrheete ise\n",
            "Sande fah s t heo ea  n r e en \n",
            "A\"  a  me eltatse eare   o  n ie or,  nangutsnt  heor e a, \n",
            "Aosor  nao e  n  ea n  ng oat om   no    \n",
            "  aa   oen dt  uh u  ast aen  s   uegail cnh\n",
            "NIts   \n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "s   fhis\n",
            "ooncl liilmrnltnduwewaya st bhrl o  \n",
            "raym aaee ra;-nreoRetgsaee\n",
            "hk d  ucutrh qut se sikat.hroilltrkeh  dris.\n",
            "eWlah   otncrow esr Savt.tholi\n",
            "BaM   arsmrus e \n",
            "l u ehd t tlh  ielono, ea veel\n",
            "Whhi fec\" aVvwoamgtsamlna ntisoslhowspn ,xeitujse \n",
            "TTBi kmchd mt an trhih  S dau  aau?Seeernetn uc,wsee\n",
            "\n",
            "thr es-sieenaan anw\n",
            "rah  arv eeedt teeiecepiae era e\n",
            "filn itne iteton ltringy tgtocohoaef easfnsds ,ehb\n",
            "Aagenrn5d ndeodchm da io sarer aakIeln et\n",
            "Wsitiwfoo  ! eo \n",
            "Whshn hntogh\n",
            " ltw avRaoe la, hnedoal gp-al !hod i  -otcsvaawnnse. n\n",
            "tVnt d, a an aIls,fsTmi! ya ytdft whathh sng'rtae aesm out y,enhhhemr\n",
            "\n",
            "dl  acthhoo   no,rtildo\n",
            "ortatena eni- Moontbothehise fi,h!so : LririMd!esf niga, n s\n",
            "TnaMS  ring\n",
            "A ls!V  Sgiusgiut iaeian tehst s tNhti a\n",
            " k sce  stih otMt,tteetli\n",
            " owT thaosuthlrl. ania e psiimod l!il nd,eo sahdniyeh;\n",
            "niaaomnd,haag noglngdila, oatddr lfe.h\n",
            "Itihlshtoiwortotolt s  of,Dawo  irrlnni! !\n",
            "\n",
            "Epoch 6/20\n",
            "85/85 [==============================] - 5s 54ms/step - loss: 2.6648\n",
            "Epoch 7/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 2.3441\n",
            "Epoch 8/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 2.1871\n",
            "Epoch 9/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 2.0685\n",
            "Epoch 10/20\n",
            "85/85 [==============================] - 5s 61ms/step - loss: 1.9637\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "ared, and seared and seared,\n",
            "And the soulless the searing the seath and seared and seed\n",
            "Which the soully the soullesss of the seares of the sear,\n",
            "The sees of the seal, and sence,\n",
            "And the sear of the searing the sees\n",
            "And the seath and seners the seared of the see\n",
            "The senes the sees the seal the sees \n",
            "\n",
            " searing the sees\n",
            "The searing the searing the seares,\n",
            "And the seath and the seating the searing,\n",
            "The seared of the searing the seared,\n",
            "And the seare, and the seares the seed\n",
            "The senes of the searing the fore\n",
            "Which the seal the sence, and seared of the sence\n",
            "The sence the seed of the seared,\n",
            "And the \n",
            "\n",
            "g the searing,\n",
            "And the searing and searing, and the sear of the seared,\n",
            "And the soulless the sear, and the seath and sones\n",
            "So the searing the sence the self\n",
            "With the ford of the searing and seath,\n",
            "And soul the searing, and soness,\n",
            "And mand the sould and sands, and the seared,\n",
            "Sut of the seating the \n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "e, and soul the sare\n",
            "In greneds and senather by the seed and the sees\n",
            "The sindest sece the sesenes, sherings the seath frames\n",
            "Me the sesering sets, the hearst,\n",
            "And where the shill, the searing,\n",
            "And this its sended, shenes the sonders,\n",
            "Sence thee will asthing is the seed\n",
            "The That is meath, say, and s\n",
            "\n",
            "nd,\n",
            "Of him stall, ast, shane, and the more,\n",
            "Sut will of the sealt, sould, for the foods!\n",
            "Sentered speraring by all the thou soulf\n",
            "These the Shay of mandes, and Arince!\n",
            "Than work of all the mand, and the sesen, the setsean, the forth seared of all ore,\n",
            "And, and action of Kighing nor the set\n",
            "To serive\n",
            "\n",
            " and this spering,\n",
            "What his seing of Thyse of Seareds\n",
            "The pring, nor all the these trought the mon\n",
            "Of Soul the wirk of sear, the sindsine\n",
            "Burent and soul, and these rines!\n",
            "Of the mondse, the say, souls not the seath the sead\n",
            "And to deartunes and the work\n",
            "As shant! Noul, and the sonder,\n",
            "Nore working \n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "th the detally, cecerirdofe,\n",
            "Intye this ligher, what erong,\n",
            "Subakness hake, amatt the same\n",
            "Woronfecest; bose that fower, yod alesh\n",
            "To keyers in the forthing-Aking;\n",
            "By lence at loffmnens, atows Shat\n",
            "Pmaparting theess there words! A will,\n",
            "Of Ilty, unevor,\n",
            "In shipl offeron! heally ustay,\n",
            "Pandoula.\n",
            "Ho T\n",
            "\n",
            "!\n",
            "And withrea eraved wat these oe thee\n",
            "And grealled, fuvine, spelfing and ingrofed;\n",
            "Do note; and thour ame delar, cold is live!\n",
            "Evoweres helf\n",
            "Tome, come of food Naithilce! Lord,\n",
            "Of Ilmor, sco' outest Dapa! gond\n",
            "'veren wathss aros toust!\n",
            "Ofith, anjonce! and bide and am ables,\n",
            "All gores wow, dearmes, \n",
            "\n",
            " thousded Imes thou willd the men thy Sonts!\n",
            "Speamne, Bugthain, thenfernded,\n",
            "Thou hashends all; than daiping givess\n",
            "Cove! PuI parifisas!\"\n",
            "Hese on biking in oferwhevedith hime.\n",
            "Be oves--enow overpelf these peath\n",
            "Sunearith, and five, mind alatreat:\n",
            "Nourghends, smold\n",
            "Lore\n",
            "Bereety, and My that Ired, OnB\n",
            "\n",
            "Epoch 11/20\n",
            "85/85 [==============================] - 4s 53ms/step - loss: 1.8829\n",
            "Epoch 12/20\n",
            "85/85 [==============================] - 5s 60ms/step - loss: 1.8044\n",
            "Epoch 13/20\n",
            "85/85 [==============================] - 5s 60ms/step - loss: 1.7467\n",
            "Epoch 14/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 1.6927\n",
            "Epoch 15/20\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 1.6470\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "he sees of the sees\n",
            "The sees of the will the sees and strings\n",
            "And the works of the sees of the sees bear the sense,\n",
            "And the wite of the sees with strings\n",
            "Of the see and the sees of the souls\n",
            "The wise of the sees of the sees\n",
            "Which beands and the faith, and the self--\n",
            "The rear the self and who sees an\n",
            "\n",
            "sees of the faith and say,\n",
            "And the soul the sees and sense,\n",
            "And the sees of the sees, and the soul the sees\n",
            "The right of the grief of the gord and shall the self-comes\n",
            "The sees the self--what is the sees,\n",
            "The soul the sees of the sees of the sees\n",
            "And the see see shall the shall seed from the sees of\n",
            "\n",
            "nd the grief of say,\n",
            "And the see shall the way of the sees\n",
            "In the sense and sense, and the sees\n",
            "Of the wise of the sees of the works of the great and sain,\n",
            "The sees of the sall the sees and sees\n",
            "The world of the sees and sees of the sees and sees,\n",
            "And the sees of the faith and say\n",
            "The prishing and g\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "ll deed who sees,\n",
            "And sure for who sark the slake the men the mankints of the souls,\n",
            "The morks the bight of all the flame\n",
            "That with benore the soul springs a self.\n",
            "There in his work of the wander him say\n",
            "The faith all the will best the viem,\n",
            "The Soul all the dowerness with grened act--\n",
            "Who world the\n",
            "\n",
            "ul, and the self\n",
            "In all the secker is such cail to sead,\n",
            "And ADHIIIAJan Vight,\" and that gain,\n",
            "The singer not more, stain it the works and wain of that wither him deed\n",
            "This is wisto to kerter farth,\n",
            "And who seh of hast which light\n",
            "The wassing sinful from all the shall soul\n",
            "In all sheating earth, the\n",
            "\n",
            "hall the shall men sees and sinds\n",
            "And all the self, and the to have makes\n",
            "The is of the will the flace in the frame,\n",
            "And the kindes with the see, and all thinks\n",
            "And all the right of the gaits,\n",
            "And the manduling mind the grief of Brahranas, and who workned how be all with clain\n",
            "Is to man from prishin\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "the mand and eres,\n",
            "To mounse of eavines not meare--\n",
            "The Unrave the from I heaver trulfing--high plading,\n",
            "High hepning them, betil our suy\n",
            "Truppedtle, cindounegn\n",
            "Known greendw, worsoul, santirg and; abdoumiy, dawer that where saips\n",
            "Wite the flisser of fixe of frame.\n",
            "And breait I whighteld spail reist\n",
            "\n",
            " howleppelf ale; resined!\n",
            "Let that in who chame are feashes,\n",
            "Muty and Loatk for hits-deivered by dies Sharry,\n",
            "But thoushinks mooth, where the gatiined\n",
            "May are do, Arshama! Whreapterung--\n",
            "Thy forled OM a and Re! This of flood!\n",
            "Know, That may, damar, thexer protts pperifiets men!\n",
            "There spreal the have\n",
            "\n",
            "y we vead secker that witlf of gase cans\n",
            "To spiee! Is the Vighes--and hereth not, geed is,\n",
            "Bouks, nor sparath\n",
            "Of Vamva, abone, and tame exer\n",
            "Exetless, nor every and rightly Make the wise\n",
            "The Unnigrceet beloring milled;\n",
            "Live doth frade, dreparkalny tundit,\n",
            "Thus and wise the worod or the boroud, gacki\n",
            "\n",
            "Epoch 16/20\n",
            "85/85 [==============================] - 4s 52ms/step - loss: 1.6070\n",
            "Epoch 17/20\n",
            "85/85 [==============================] - 5s 58ms/step - loss: 1.5750\n",
            "Epoch 18/20\n",
            "85/85 [==============================] - 5s 61ms/step - loss: 1.5431\n",
            "Epoch 19/20\n",
            "85/85 [==============================] - 5s 60ms/step - loss: 1.5201\n",
            "Epoch 20/20\n",
            "85/85 [==============================] - 5s 61ms/step - loss: 1.5006\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "the self to the heart the souls the grief\n",
            "In the soul the sense, and the soul the self,\n",
            "The souls and sense, and sees in the soul\n",
            "The soul the sees of the sees the will the souls the soul and sees,\n",
            "And the wise of the soul of the soul\n",
            "The sees of the soul the soul which lives,\n",
            "The self the shall the\n",
            "\n",
            "es of all the reatures of the soul and say\n",
            "Who sees of the sees of the faith,\n",
            "And the soul the too, and the soul the see\n",
            "The soul the sees of the soul the sees\n",
            "The shall the says and waster to Me,\n",
            "Who seed of the soul the sees and say\n",
            "The soul the sees and strings the souls the sees\n",
            "The sense of the\n",
            "\n",
            "he sense, and with be soul and sees\n",
            "To shall the sees of the soul sees the sees,\n",
            "And who seek of the sees of the souls\n",
            "The self the true see the sees\n",
            "Which the self the sees of the souls the great the sees,\n",
            "The soul of the sees of the faith,\n",
            "The soul thou shall the bears to Me!\n",
            "The soul of the sees \n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Somprahma's the shall be the Soul,\n",
            "So in the soul of the works and the works\n",
            "So is not he who ame arith the quilities, and faith,\n",
            "And singer the world of the love,\n",
            "And such and wealth, and the mould\n",
            "The man, and arcest--rear, and the self,\n",
            "The evil the mould of the Dear of the great shall from all t\n",
            "\n",
            "l the trim in the sees and sain,\n",
            "The frame of King, and from the know\n",
            "His of the wise for all the qule,\n",
            "And toons thou amarness, spranget and stame;\n",
            "And the worshippes to the world with bath is the tree with the soul from deed,\n",
            "And dies the peace of Me! That though the soul\n",
            "The soul the from great w\n",
            "\n",
            "ith shape, seeping for self,\n",
            "The man is the lives of the stine the flesh,\n",
            "The say of lore, so to the Prince!\n",
            "To seast and stark with for thou still the flesh\n",
            "In all things and worshippess of the soul;\n",
            "But springs the flame of the gold\n",
            "The right with his who comes all the faith,\n",
            "And they birth and th\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "he friete--\n",
            "Plead arit enidreves, the Soul and bodsing, huch if heme rease,\n",
            "Unbogeth the prital, sotter to Me.\n",
            "Muty pasuring thou sahing his heed;\n",
            "And, whreace come of rubknester; for ligts!\n",
            "HEtat O which bijther, dear, ever what voubtion and dien.\n",
            "Yugh! Such earther sleath. The Lord of Paing, and P\n",
            "\n",
            "every are Thyself,\n",
            "Vutersing His upon fear! Wotse--this way,\n",
            "O Kuht Thou Brom, emparishand buch racrifice\n",
            "Unbode to the, and Belnige and stiln\n",
            "Which lives in Night of ho dore\n",
            "And illlade, \"Osted, inty and, all belignt\n",
            "Benoling bittoul and sacti.[FN#2]\n",
            "Eting feapents the Soul shilf derick\n",
            "Are wind, w\n",
            "\n",
            "holying, by bond;\n",
            "The Upoon a is gord, Amriedt: mein things.\n",
            "So my farled, the trim the goust.\n",
            "Thou Their--where to My stald, 'wTill sortely spred--\n",
            "How ever minget on a wouns, soul a im its no Me! Dlay\n",
            "Being Me, chailed hose some sogh My spoous\n",
            "Filless or excrilly; and the tork be!\n",
            "Impering upfors,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [0.3, 0.5, 0.2, 0.1]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "To recreate the model on your own computer, after installing textgenrnn and TensorFlow, you can create a Python script with:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Zjtsb_Dgj-",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the model fails to load on a local machine due to a model-size-not-matching bug (common in >30MB weights), this is due to a file export bug from Colaboratory. To work around this issue, save the weights to Google Drive with the two cells below and download from there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ5i_441Jqjp",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isOatxAGJunx",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-IzscxUHmAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR4_XJpfKAIn",
        "colab_type": "code",
        "outputId": "f70ce499-1062-4968-8423-c7dbcd71cc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "uploaded = drive.CreateFile({'title': '{}_weights.hdf5'.format(model_name)})\n",
        "uploaded.SetContentFile('{}_weights.hdf5'.format(model_name))\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1b6T6M32YnXs-c0NB-PEi6MhAdCuG7RHy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}